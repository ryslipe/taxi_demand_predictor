from datetime import datetime, timedelta
import pandas as pd
import pytz


from hsfs.feature_view import FeatureView
from hsfs.feature_group import FeatureGroup

import src.config as config
from src.inference import get_feature_store

# create this function over in config
def get_or_create_feature_group(
        name: str,
        version: int,
        description: str,
        primary_key: list,
        event_time: str,

) -> FeatureGroup:
    """Connects to the feature store and returns a pointer to the given
    feature group `name`

    Args:
        name (str): name of the feature group
        version (Optional[int], optional): _description_. Defaults to 1.

    Returns:
        hsfs.feature_group.FeatureGroup: pointer to the feature group
    """
    return get_feature_store().get_or_create_feature_group(
        name=name,
        version=version,
        description=description,
        primary_key=primary_key,
        event_time=event_time,
        
    )

# load predictions and actual values from the store
def load_predictions_and_actuals_from_store(
    from_date: datetime,
    to_date: datetime,
) -> pd.DataFrame:
    """Fetches model predictions and actuals values from
    `from_date` to `to_date` from the Feature Store and returns a dataframe

    Args:
        from_date (datetime): min datetime for which we want predictions and
        actual values

        to_date (datetime): max datetime for which we want predictions and
        actual values

    Returns:
        pd.DataFrame: 4 columns
            - `pickup_location_id`
            - `predicted_demand`
            - `pickup_hour`
            - `rides`
    """
    # the two feature groups we need to merge
    # predictions feature group
    predictions_fg = get_or_create_feature_group(
        name=config.FEATURE_GROUP_MODEL_PREDICTIONS,
        version=config.FEATURE_GROUP_MODEL_VERSION,
        description= 'Predictions generated by model',
        primary_key= ['pickup_location_id', 'pickup_ts'],
        event_time= 'pickup_ts'
    )
    # actuals feature group
    actuals_fg = get_or_create_feature_group(
        name=config.FEATURE_GROUP_NAME,
        version=config.FEATURE_GROUP_VERSION,
        description="Time-series data at hourly frequency",
        primary_key = ['pickup_location_id', 'pickup_ts'],
        event_time='pickup_ts'
    )

    # query to join the 2 features groups by `pickup_hour` and `pickup_location_id`
    # time stamps
    from_ts = int(from_date.timestamp() * 1000)
    to_ts = int(to_date.timestamp() * 1000)
    # select all columns from predictions feature group and join on common columns then filter to our time frame
    query = predictions_fg.select_all() \
        .join(actuals_fg.select(['pickup_location_id', 'pickup_ts', 'rides']),
              on=['pickup_ts', 'pickup_location_id'], prefix=None) \
        .filter(predictions_fg.pickup_ts >= from_ts) \
        .filter(predictions_fg.pickup_ts <= to_ts)
    
    # create feature view if it does not exist
    feature_store = get_feature_store()
    try:
        feature_store.create_feature_view(
            name=config.MONITORING_FV_NAME,
            version=config.MONITORING_FV_VERSION,
            query=query
        )
    except Exception as e:
        print(f'Failed to create feature view. Error: {e}')
        if "already exists" in str(e):
            print('Feature view already existed. Skip creation.')
        else:
            raise
    
    # feature view
    monitoring_fv = feature_store.get_feature_view(
        name=config.MONITORING_FV_NAME,
        version=config.MONITORING_FV_VERSION
    )

    # get batch of data
    # fetch predicted and actual values 
    monitoring_df = monitoring_fv.get_batch_data(
        start_time=from_date - timedelta(days=7),
        end_time=to_date + timedelta(days=7),
    )

    # filter data to the time period we are interested in
    pickup_ts_from = int(from_date.timestamp() * 1000)
    pickup_ts_to = int(to_date.timestamp() * 1000)
    monitoring_df = monitoring_df[monitoring_df.pickup_ts.between(pickup_ts_from, pickup_ts_to)]

    return monitoring_df




