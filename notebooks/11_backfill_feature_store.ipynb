{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use the feature store in the API calls we will need the project name and the API key. I am using CAPS for hopsworks variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project name for API call feature store\n",
    "HOPSWORKS_PROJECT_NAME = 'taxi_demand_rs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the API Key from the .env File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **dotenv** library allows us to load variables from external files as environment variables. Environment variables means we can access them using the **os** module.\n",
    "\n",
    "A **.env** file is a plain text file that stores API keys and other sensitive information. This file is created within our project parent directory (not in the notebooks or src folders). We store it in this file because hardcoding an API key is a serious security violation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from src.paths import PARENT_DIR\n",
    "\n",
    "# specify the path where the file is\n",
    "load_dotenv(PARENT_DIR / '.env')\n",
    "\n",
    "HOPSWORKS_API_KEY = os.environ['HOPSWORKS_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Commiting to Git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Never commit the API key to GitHub repository. For this reason, we create a **gitignore** file. This file is located in the parent directory (not src, data, notebooks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetching Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the **load_raw_data** function from the **src.data** script to load in raw data from 2022-today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading files from 2022 to 2024.\n",
      "File 2022-01 was already in local storage\n",
      "File 2022-02 was already in local storage\n",
      "File 2022-03 was already in local storage\n",
      "File 2022-04 was already in local storage\n",
      "File 2022-05 was already in local storage\n",
      "File 2022-06 was already in local storage\n",
      "File 2022-07 was already in local storage\n",
      "File 2022-08 was already in local storage\n",
      "File 2022-09 was already in local storage\n",
      "File 2022-10 was already in local storage\n",
      "File 2022-11 was already in local storage\n",
      "File 2022-12 was already in local storage\n",
      "File 2023-01 was already in local storage\n",
      "File 2023-02 was already in local storage\n",
      "File 2023-03 was already in local storage\n",
      "File 2023-04 was already in local storage\n",
      "File 2023-05 was already in local storage\n",
      "File 2023-06 was already in local storage\n",
      "File 2023-07 was already in local storage\n",
      "File 2023-08 was already in local storage\n",
      "File 2023-09 was already in local storage\n",
      "File 2023-10 was already in local storage\n",
      "File 2023-11 was already in local storage\n",
      "File 2023-12 was already in local storage\n",
      "File 2024-01 was already in local storage\n",
      "File 2024-02 was already in local storage\n",
      "File 2024-03 was already in local storage\n",
      "File 2024-04 was already in local storage\n",
      "File 2024-05 was already in local storage\n",
      "File 2024-06 was already in local storage\n",
      "File 2024-07 was already in local storage\n",
      "Downloading file 2024-08\n",
      "2024-08 file is not available\n",
      "Downloading file 2024-09\n",
      "2024-09 file is not available\n",
      "Downloading file 2024-10\n",
      "2024-10 file is not available\n",
      "Downloading file 2024-11\n",
      "2024-11 file is not available\n",
      "Downloading file 2024-12\n",
      "2024-12 file is not available\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from src.data import load_raw_data\n",
    "\n",
    "# use load_raw_data\n",
    "# starting year of data fetching\n",
    "start_year = 2022\n",
    "# ending year will be the current year\n",
    "end_year = datetime.now().year   \n",
    "print(f'Downloading files from {start_year} to {end_year}.')\n",
    "\n",
    "# set up an empty dataframe to be filled by function\n",
    "rides = pd.DataFrame()\n",
    "\n",
    "# loop to download all wanted data\n",
    "for year in range(start_year, end_year+1):\n",
    "    # download data for the year\n",
    "    rides_one_year = load_raw_data(year)\n",
    "\n",
    "    # append rows\n",
    "    rides = pd.concat([rides, rides_one_year])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101372930\n"
     ]
    }
   ],
   "source": [
    "print(len(rides))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform the Data into Time Series Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the data needs to be transformed into time series data. We can use the **transform_raw_data_into_ts_data** from the **data.py** module for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:06<00:00, 43.92it/s]\n"
     ]
    }
   ],
   "source": [
    "from src.data import transform_raw_data_into_ts_data\n",
    "\n",
    "ts_data = transform_raw_data_into_ts_data(rides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>rides</th>\n",
       "      <th>pickup_location_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 01:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 02:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 03:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997475</th>\n",
       "      <td>2024-07-31 19:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997476</th>\n",
       "      <td>2024-07-31 20:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997477</th>\n",
       "      <td>2024-07-31 21:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997478</th>\n",
       "      <td>2024-07-31 22:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997479</th>\n",
       "      <td>2024-07-31 23:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5997480 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                pickup_hour  rides  pickup_location_id\n",
       "0       2022-01-01 00:00:00      0                   1\n",
       "1       2022-01-01 01:00:00      0                   1\n",
       "2       2022-01-01 02:00:00      0                   1\n",
       "3       2022-01-01 03:00:00      0                   1\n",
       "4       2022-01-01 04:00:00      1                   1\n",
       "...                     ...    ...                 ...\n",
       "5997475 2024-07-31 19:00:00      2                 265\n",
       "5997476 2024-07-31 20:00:00      1                 265\n",
       "5997477 2024-07-31 21:00:00      4                 265\n",
       "5997478 2024-07-31 22:00:00      2                 265\n",
       "5997479 2024-07-31 23:00:00      1                 265\n",
       "\n",
       "[5997480 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_data['pickup_hour'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we connect to our project on Hopsworks. To do so, we will use the variable **HOPSWORKS_PROJECT_NAME** that we created at the top of this notebook along with the API key that we read in using **load_dotenv** called, **HOPSWORKS_API_KEY**. To connect to the project we import hopsworks then use **hopsworks.login()** with the two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1049751\n"
     ]
    }
   ],
   "source": [
    "# connect to our project\n",
    "project = hopsworks.login(\n",
    "    project = HOPSWORKS_PROJECT_NAME,\n",
    "    api_key_value= HOPSWORKS_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have connected to the project we have the ability to use **project.get_feature_store()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "# create feature store\n",
    "feature_store = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save Features to the Feature Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save data to the feature store we need to use **feature groups**. A feature group is just a table of features with predictive power for our model. Each group has a **primary key** and optionally an **event_time** column and a **partition key**. These are certain columns in our data. The partition key helps with queries such as a location id. \n",
    "\n",
    "**Primary Key** - The primary key ensures each row in the data is unique. In our example we have pickup_hour, pickup_location_id and rides. The pickup_hour, pickup_location_id and number of rides can all be used more than once. For this reason, the primary key will be **['pickup_location_id', 'pickup_hour']** because this ensures each row of the data is unique based on the location and time of the ride.\n",
    "\n",
    "**Partition Key** - This helps query the data. We can use either pickup_hour or pickup_location_id if we want to query based on hour or position. We can also use both for multidimensional partitioning. I will not be starting out with a partition key since it is optional. \n",
    "\n",
    "To use a feature group we need to set the **name** and **version**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature group name and version\n",
    "FEATURE_GROUP_NAME = 'time_series_hourly_feature_group'\n",
    "FEATURE_GROUP_VERSION = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the feature group\n",
    "feature_group = feature_store.get_or_create_feature_group(\n",
    "    name = FEATURE_GROUP_NAME,\n",
    "    version = 1,\n",
    "    description = 'Hourly time series data',\n",
    "    primary_key = ['pickup_location_id', 'pickup_hour'],\n",
    "    event_time = 'pickup_hour'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the feature group is created we save our data to it. We use **write_options = {'wait_for_job':False}** so we can keep working as the data is inserted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95e3a5b54a154184b09f5d9a103d430b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/5997480 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: time_series_hourly_feature_group_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/1049751/jobs/named/time_series_hourly_feature_group_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x1d93fb0b2e0>, None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add data to the feature group\n",
    "feature_group.insert(ts_data, write_options={'wait_for_job':False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
